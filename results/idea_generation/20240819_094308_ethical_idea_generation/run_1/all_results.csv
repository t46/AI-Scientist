paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
20240819_094329_learning_rate_schedule,"The paper investigates the impact of various learning rate schedules (StepLR, CyclicLR, OneCycleLR) on the performance of diffusion models, specifically Denoising Diffusion Probabilistic Models (DDPMs). The study aims to identify the optimal learning rate schedule by evaluating metrics such as training time, evaluation loss, inference time, and KL divergence across multiple 2D datasets.","['Can the authors provide a more in-depth analysis of why specific learning rate schedules perform better in certain contexts?', 'Would additional experiments on more complex datasets yield different insights?', 'Why were these specific learning rate schedules chosen for diffusion models?', 'Can the authors provide more complex datasets and additional evaluation metrics to support their findings?', 'What theoretical insights or analysis can be provided to explain the empirical results?', 'How do the results generalize to more complex datasets beyond the 2D datasets used in the study?', 'Can the authors discuss the potential impact of other hyperparameters (e.g., batch size, optimizer settings) on the performance of diffusion models?']","['The study is limited by the simplicity of the datasets used and the superficial analysis of the results.', 'The evaluation metrics used, such as MSE and KL divergence, may not fully reflect the quality of the generated samples.', 'The paper lacks sufficient discussion on the methodology and results.']",False,2,2,2,3,4,"['The topic is relevant and addresses a critical aspect of training diffusion models.', 'The experimental setup is detailed, including multiple datasets and evaluation metrics.', 'The study offers practical recommendations for optimizing diffusion model training.']","['The study lacks significant originality, primarily replicating existing learning rate schedules and applying them to diffusion models.', 'The analysis of the results is superficial, lacking depth in explaining why certain schedules perform better.', 'The experiments are conducted on relatively simple 2D datasets, which may not fully capture the complexities of real-world data.', 'The paper lacks exploration of more advanced learning rate schedules, such as cosine annealing or custom schedules tailored to specific datasets.', 'The discussion on the methodology and results is insufficient, lacking depth and critical analysis.', 'The paper does not provide code or implementation details, which limits reproducibility.']",2,2,2,2,Reject
20240819_103037_controllable_generation,"The paper proposes a novel approach to controllable generation in diffusion models by integrating a conditional embedding module into the MLPDenoiser class. This method aims to generate samples biased towards specific modes or patterns in the data. The approach is validated through experiments on 2D datasets, showing improvements in KL divergence and visual quality compared to a baseline model.","['Can the authors provide more detailed comparisons with other state-of-the-art methods for controllable generation?', 'Are there plans to test the proposed method on more complex and higher-dimensional datasets?', 'Could the authors include additional quantitative metrics (e.g., FID score) in their evaluation to provide a more comprehensive assessment of the generated samples?', 'Can the authors provide more detailed explanations of the conditional embedding module and its integration into the MLPDenoiser class?', 'What are the limitations and potential negative societal impacts of the proposed method?']","['The increased training and inference times due to the conditional embeddings could be a significant drawback for large-scale applications.', 'The performance on more complex datasets needs to be validated to establish the robustness and scalability of the proposed method.']",False,2,2,2,3,4,"['Addresses an important challenge in generative modeling: controllable generation in diffusion models.', 'The integration of a conditional embedding module into the MLPDenoiser class is a novel idea that could potentially improve the quality and diversity of generated samples.', 'The paper is well-written and clearly organized, making it easy to follow the proposed methodology and experiments.']","['The experiments are limited to simple 2D datasets, which may not fully demonstrate the scalability and robustness of the proposed method.', 'The paper lacks a detailed comparison with other state-of-the-art methods for controllable generation, such as conditional GANs and VAEs.', 'The evaluation metrics are somewhat limited. While KL divergence and visual inspection are useful, additional quantitative metrics (e.g., FID score) would strengthen the evaluation.', 'The methodology section lacks sufficient detail, making it difficult to fully understand and reproduce the work.', 'The increased training and inference times are significantly higher for the proposed method, which might limit its practicality for large-scale applications.']",2,2,3,2,Reject
