paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
20240819_174707_learning_rate_schedule,"This paper investigates the impact of different adaptive learning rate schedules on the performance of diffusion models. The authors compare StepLR and CyclicLR schedules with a baseline, evaluating their effects on the final estimated KL divergence, training time, and inference time across multiple datasets.","['Can the authors provide more comprehensive ablation studies, including other learning rate schedules like cosine annealing or exponential decay?', 'Could the authors give more details about the model architecture and training setup to ensure the results are reproducible?', 'The results show limited improvements in KL divergence with adaptive learning rate schedules. Can the authors discuss this in more detail and provide potential reasons or solutions?', ""Why were only StepLR and CyclicLR chosen for comparison? Wouldn't including other schedules like cosine annealing and exponential decay provide a more comprehensive study?"", 'Can the authors provide more theoretical background or justification for the choices made in the experimental setup?', 'How do the authors plan to address the increased computational cost associated with adaptive learning rate schedules?', 'Can the authors provide a more detailed theoretical analysis of why certain learning rate schedules perform better or worse in specific scenarios?', 'Is there a specific reason the datasets chosen were primarily synthetic and not more diverse or real-world datasets?']","['The paper does not comprehensively explore a variety of learning rate schedules, limiting its contribution to the field.', 'The increased computational cost of adaptive learning rate schedules is a significant limitation that is not adequately addressed.', 'The results are not consistent across all datasets, indicating that the findings may be dataset-dependent.']",False,2,2,2,3,4,"['The paper addresses a relevant problem in optimizing diffusion models, which is critical for improving generative model performance.', 'The experimental setup includes a variety of datasets, providing a broad perspective on the impact of different learning rate schedules.']","['The originality of the paper is limited since comparing learning rate schedules is not a novel contribution in the field of machine learning.', 'The paper lacks detailed ablation studies to explore the impact of other potential learning rate schedules like cosine annealing or exponential decay.', 'The methodology section is not detailed enough to ensure reproducibility. Details such as the specific architecture parameters and training procedures are not sufficiently described.', 'The results indicate that the adaptive learning rate schedules do not consistently outperform the baseline in terms of KL divergence, raising questions about the practical benefits of these schedules.', 'The increased computational cost associated with adaptive learning rate schedules is a significant limitation that is not adequately addressed.']",2,2,3,2,Reject
20240819_183032_controllable_mode_biasing,"The paper proposes a novel approach to controllable mode biasing in diffusion models by integrating a learnable bias mechanism into the noise scheduler. This mechanism dynamically adjusts noise levels to emphasize specific modes of interest during generation. The approach is validated through experiments on synthetic 2D datasets, showing improvements in mode-specific generation as measured by KL divergence.","['How does the proposed method perform on more complex, real-world datasets?', 'Can the authors provide a more detailed comparison with other state-of-the-art generative models?', ""What are the potential limitations of the bias mechanism, and how might it affect the model's performance in different scenarios?"", 'Can you provide more detailed explanations or visualizations to clarify how the bias mechanism is integrated into the noise scheduler?', 'Why does the KL divergence increase for certain datasets like Circle and Line? Can the authors provide more insight or visualizations to explain these results?', 'What specific measures can be taken to reduce the increased training and inference times introduced by the bias mechanism?', 'Can the authors include the missing figures and ensure the text is free of placeholders?']","['The paper should include a more detailed discussion on the limitations and broader applicability of the proposed method.', 'The effectiveness of the method on more complex datasets and different model architectures needs to be explored.', 'The increased computational cost is a significant limitation that needs to be addressed. The paper should discuss potential optimizations or alternative approaches to mitigate this issue.']",False,2,2,2,3,4,"['Addresses a relevant and challenging problem in generative modeling: controlling the generation process to emphasize specific data modes.', 'The introduction of a learnable bias mechanism into the noise scheduler is a novel idea.', 'Extensive experiments are conducted to validate the proposed method, providing quantitative metrics like KL divergence to assess performance.']","[""Experiments are limited to synthetic 2D datasets, which may not fully demonstrate the method's effectiveness in real-world scenarios."", 'The comparative analysis with other advanced generative models is insufficient, and the results do not consistently show significant improvement across all datasets.', 'KL divergence improvements are mixed, with some datasets showing worse performance compared to the baseline.', 'The paper lacks a detailed discussion on broader applicability, potential limitations, and the impact on more complex datasets.', 'The mathematical formulation of the bias mechanism and its integration into the noise scheduler is not detailed enough.', ""The presentation of the paper is suboptimal, with missing figures and placeholders in the text (e.g., 'Figure ??')."", 'The paper lacks a thorough comparison with related work and does not adequately cite relevant literature.']",3,2,2,3,Reject
