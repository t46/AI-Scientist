paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
20240820_094142_learning_rate_schedule,"The paper investigates the impact of various learning rate schedules on the performance of Denoising Diffusion Probabilistic Models (DDPMs) for generating 2D datasets. It evaluates advanced learning rate schedules, including ExponentialLR, ReduceLROnPlateau, and CosineAnnealingLR, to improve model performance and training efficiency. The results indicate that appropriate learning rate scheduling can significantly enhance sample quality and reduce training time.","['Can the authors provide more details about the model architecture and training process?', 'Why were only simple 2D datasets used for the experiments?', 'Can the authors provide more insights or theoretical justification for why CosineAnnealingLR performs better in most cases?', 'How would the proposed learning rate schedules perform on more complex and higher-dimensional datasets?', 'Can you provide more details on why you chose the specific 2D datasets and how they relate to real-world applications?', 'Have you considered evaluating the learning rate schedules on more complex datasets or higher-dimensional data?', 'Can you provide more theoretical analysis or insights into why certain learning rate schedules perform better than others for DDPMs?', 'Are there any specific reasons for choosing the particular learning rate schedules evaluated in this study over others?']","['The use of simple 2D datasets limits the generalizability of the findings.', 'The paper lacks a detailed analysis of why certain learning rate schedules perform better.', 'The study is limited to 2D datasets, which may not fully represent the challenges in more complex real-world applications.', 'The paper focuses on empirical results without introducing new theoretical insights or methodologies.', 'The training times for the CosineAnnealingLR schedule are longer, which may be a consideration for large-scale applications.']",False,2,2,2,3,4,"['The paper addresses a relevant and practical issue in training DDPMs.', 'Provides a comprehensive empirical evaluation of different learning rate schedules on multiple 2D datasets.', 'Successfully demonstrates that appropriate learning rate scheduling can significantly enhance sample quality and reduce training time.']","['The paper lacks novelty as it does not introduce any new techniques or approaches.', 'The experimental design is shallow, using only simple 2D datasets, which limits the generalizability of the findings.', 'Key details about the model architecture and training process are missing, making it difficult to reproduce the results.', 'The analysis of the results is not sufficiently detailed, and the paper does not provide a deep understanding of why certain schedules perform better.', 'The originality of the paper is moderate, as optimizing learning rate schedules is a well-known technique in machine learning.', 'Some parts of the paper, such as the detailed working of learning rate schedules, could be explained more clearly.']",2,2,3,2,Reject
